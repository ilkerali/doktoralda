import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from matplotlib.colors import ListedColormap
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
import seaborn as sns
from IPython.display import display
from matplotlib import pyplot as plt
from sklearn.decomposition import FastICA

dataset = pd.read_csv('WineQT.csv')
X = dataset.iloc[:, :-2].values
y = dataset.iloc[:, -2].values
print(dataset.shape)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

ss_X = StandardScaler()
X_train = ss_X.fit_transform(X_train)
X_test = ss_X.transform(X_test)
print(X_train.shape)

lda_test = LDA(n_components=None)
lda_test.fit(X_train, y_train)
sns.set(style='whitegrid')
plt.plot(np.cumsum(lda_test.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance')
display(plt.show())

evr = lda_test.explained_variance_ratio_
cvr = np.cumsum(lda_test.explained_variance_ratio_)

lda_df = pd.DataFrame()
lda_df['Cumulative Variance Ratio'] = cvr
lda_df['Explained Variance Ratio'] = evr
display(lda_df.head(15))

lda = LDA(n_components=2)
X_train_lda = lda.fit_transform(X_train, y_train)
X_test_lda = lda.transform(X_test)

param_grid = [
    {'C': [0.1, 1, 10, 100, 1000],
     'gamma': [0.0001, 0.001, 0.01, 0.1, 1],
     'kernel': ['rbf']},
    {'C': [0.1, 1, 10, 100, 1000],
     'kernel': ['linear']},
]
grid = GridSearchCV(SVC(), param_grid, verbose=2)
grid.fit(X_train_lda, y_train)
classifier = grid.best_estimator_

y_pred = classifier.predict(X_test_lda)

print('Confusion matrix:\n', metrics.confusion_matrix(y_test, y_pred))
print(metrics.classification_report(y_test, y_pred))

X_set, y_set = X_test_lda, y_test
X1, X2 = np.meshgrid(np.arange(start=X_set[:, 0].min() - 1, stop=X_set[:, 0].max() + 1, step=0.01),
                     np.arange(start=X_set[:, 1].min() - 1, stop=X_set[:, 1].max() + 1, step=0.01))
plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha=0.75, cmap=ListedColormap(('red', 'green', 'blue')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c=ListedColormap(('red', 'green', 'blue'))(i), label=str(j))
plt.title('SVC (Test set)')
plt.xlabel('LD1')
plt.ylabel('LD2')
plt.legend()
plt.show()


ica = FastICA(n_components=2)
components = ica.fit_transform(X_train)
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.scatter(X_train[:, 0], X_train[:, 1])
plt.title('Original Data')
plt.subplot(1, 2, 2)
plt.scatter(components[:, 0], components[:, 1])
plt.title('ICA Components')
plt.tight_layout()
plt.show()
